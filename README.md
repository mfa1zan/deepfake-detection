# ğŸ­ Deepfake Video Detection Using CNN-LSTM

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://python.org)
[![Flask](https://img.shields.io/badge/Flask-2.0+-green.svg)](https://flask.palletsprojects.com/)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.0+-orange.svg)](https://tensorflow.org)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

A sophisticated deepfake video detection system powered by CNN-LSTM neural networks that analyzes facial landmarks to classify videos as real or fake with high accuracy.

## ğŸ¯ Overview

This project implements a state-of-the-art deepfake detection system that:

- ğŸ” Extracts facial landmarks from videos using dlib
- ğŸ§  Employs CNN-LSTM architecture for spatial-temporal analysis
- ğŸŒ Provides a user-friendly Flask web interface
- âš¡ Delivers real-time predictions with confidence scores

## ğŸ—„ï¸ Dataset

**Source:** [FaceForensics++](https://github.com/ondyari/FaceForensics) dataset

### Dataset Details:

- ğŸ“Š **Total Videos:** 2,000 (1,000 real + 1,000 fake)
- ğŸ¯ **Training:** 70% (1,400 videos)
- ğŸ§ª **Testing:** 20% (400 videos)
- âœ… **Validation:** 10% (200 videos)

> **Note:** Request access via the [FaceForensics++ website](https://github.com/ondyari/FaceForensics) and download using their provided script.

## ğŸ”„ Project Workflow

### 1. ğŸ“ Data Preparation

- Extract 68 facial landmarks from each video frame
- Save landmarks as `.npy` files for efficient processing
- Normalize landmark data for optimal model performance

### 2. ğŸ‹ï¸ Model Training

- Utilize CNN-LSTM architecture for spatial-temporal feature learning
- Train on normalized landmark sequences
- Validate performance on held-out validation set

### 3. ğŸ¯ Prediction Pipeline

- Upload video via intuitive web interface
- Real-time facial landmark extraction and normalization
- Generate prediction with confidence scores

## ğŸ“ Repository Structure

```
Flask_app/
â”‚
â”œâ”€â”€ ğŸ app.py                    # Flask application main file
â”œâ”€â”€ ğŸ¬ uploaded_video.py         # Video processing and prediction logic
â”œâ”€â”€ ğŸ“‹ requirements.txt          # Project dependencies
â”œâ”€â”€ ğŸ“– README.md                 # Project documentation
â”‚
â”œâ”€â”€ ğŸ¤– models/                   # Model weights and data
â”‚   â”œâ”€â”€ deepfake_landmark_lstm_cnn_model.h5
â”‚   â”œâ”€â”€ min_val.npy
â”‚   â”œâ”€â”€ max_val.npy
â”‚   â””â”€â”€ shape_predictor_68_face_landmarks.dat
â”‚
â”œâ”€â”€ ğŸ¨ static/                   # Static web assets
â”‚   â”œâ”€â”€ css/                     # Stylesheets
â”‚   â”œâ”€â”€ js/                      # JavaScript files
â”‚   â”œâ”€â”€ images/                  # Image assets
â”‚   â””â”€â”€ uploads/                 # Uploaded video storage
â”‚
â””â”€â”€ ğŸ“„ templates/                # HTML templates
    â””â”€â”€ index.html
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8+
- pip package manager

### Installation

1. **Clone the repository**

   ```bash
   git clone https://github.com/mfa1zan/deepfake-detection.git
   cd deepfake-detection
   ```

2. **Set up virtual environment**

   ```bash
   python3 -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies**

   ```bash
   pip install -r requirements.txt
   ```

4. **Download model files**

   - Place your trained model files (`.h5`, `.npy`, `.dat`) in the `models/` directory
   - Contact the repository maintainer for access to pre-trained models

5. **Run the application**

   ```bash
   python3 app.py
   ```

6. **Access the web interface**
   - Open your browser and navigate to `http://127.0.0.1:5000`
   - Upload a video and get instant deepfake detection results!

## ğŸ® Usage

1. **Upload Video:** Select an MP4, AVI, or MOV file
2. **Processing:** The system extracts facial landmarks automatically
3. **Detection:** Get real-time classification results
4. **Results:** View prediction labels, confidence scores, and detailed analysis

## ğŸ”§ API Endpoints

| Endpoint  | Method | Description                 |
| --------- | ------ | --------------------------- |
| `/`       | GET    | Main web interface          |
| `/upload` | POST   | Upload video file           |
| `/detect` | POST   | Process and detect deepfake |

## ğŸ“Š Model Performance

- **Architecture:** CNN-LSTM hybrid network
- **Input:** Normalized facial landmark sequences
- **Output:** Binary classification (Real/Fake) with confidence scores
- **Features:** Temporal consistency analysis across video frames

## âš ï¸ Important Notes

- ğŸ“¦ Model files (`.h5`, `.npy`) are excluded from the repository due to size constraints
- ğŸ”— Contact the maintainer for access to pre-trained models
- ğŸ“š Training notebooks and preprocessing scripts available upon request
- ğŸ¯ Supports common video formats: MP4, AVI, MOV

> **Note:** This detector was developed and trained on my local machine, so results may not be state-of-the-art or perfect. Use accordingly.

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request. For major changes, please open an issue first to discuss what you would like to change.

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgements

- **Dataset:** [FaceForensics++](https://github.com/ondyari/FaceForensics) team
- **Landmark Detection:** [dlib](http://dlib.net/) shape predictor
- **Deep Learning:** [TensorFlow](https://tensorflow.org/) and [Keras](https://keras.io/)
- **Web Framework:** [Flask](https://flask.palletsprojects.com/)

## ğŸ“ Contact

For questions, suggestions, or collaboration opportunities, please reach out:

- ğŸ“§ Email: me.faizan25@gmail.com
- ğŸ’¼ LinkedIn: https://www.linkedin.com/in/muhammad-faizan-ba5587316/
- ğŸ™ GitHub: https://github.com/mfa1zan

---

â­ **Star this repository if you found it helpful!** â­
